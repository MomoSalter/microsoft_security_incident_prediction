{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb3a93cc",
   "metadata": {},
   "source": [
    "## data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9444e380",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_data = pd.read_parquet('data/processed/train_data.parquet')\n",
    "test_data  = pd.read_parquet('data/processed/test_data.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e889fcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IncidentId</th>\n",
       "      <th>IncidentGrade</th>\n",
       "      <th>evidence_count</th>\n",
       "      <th>DetectorId_nunique</th>\n",
       "      <th>AlertTitle_nunique</th>\n",
       "      <th>DeviceId_nunique</th>\n",
       "      <th>Sha256_nunique</th>\n",
       "      <th>IpAddress_nunique</th>\n",
       "      <th>Url_nunique</th>\n",
       "      <th>AccountSid_nunique</th>\n",
       "      <th>...</th>\n",
       "      <th>EntityType_Url</th>\n",
       "      <th>EntityType_User</th>\n",
       "      <th>EvidenceRole_Impacted</th>\n",
       "      <th>EvidenceRole_Related</th>\n",
       "      <th>SuspicionLevel_Incriminated</th>\n",
       "      <th>SuspicionLevel_Suspicious</th>\n",
       "      <th>LastVerdict_Malicious</th>\n",
       "      <th>LastVerdict_NoThreatsFound</th>\n",
       "      <th>LastVerdict_Other</th>\n",
       "      <th>LastVerdict_Suspicious</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>TruePositive</td>\n",
       "      <td>29997</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>874</td>\n",
       "      <td>1</td>\n",
       "      <td>148</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>9081</td>\n",
       "      <td>9084</td>\n",
       "      <td>20913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>BenignPositive</td>\n",
       "      <td>20525</td>\n",
       "      <td>113</td>\n",
       "      <td>934</td>\n",
       "      <td>11</td>\n",
       "      <td>1881</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>320</td>\n",
       "      <td>5484</td>\n",
       "      <td>15041</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20453.0</td>\n",
       "      <td>6645.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13814.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>TruePositive</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>BenignPositive</td>\n",
       "      <td>12252</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2474</td>\n",
       "      <td>3</td>\n",
       "      <td>1721</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1737</td>\n",
       "      <td>3477</td>\n",
       "      <td>8775</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>TruePositive</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 156 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   IncidentId   IncidentGrade  evidence_count  DetectorId_nunique  \\\n",
       "0           0    TruePositive           29997                   6   \n",
       "1           2  BenignPositive           20525                 113   \n",
       "2           3    TruePositive               3                   1   \n",
       "3           7  BenignPositive           12252                   8   \n",
       "4           8    TruePositive               6                   2   \n",
       "\n",
       "   AlertTitle_nunique  DeviceId_nunique  Sha256_nunique  IpAddress_nunique  \\\n",
       "0                   6                 1               1                874   \n",
       "1                 934                11            1881                  3   \n",
       "2                   1                 1               1                  2   \n",
       "3                  19                 3               3               2474   \n",
       "4                   2                 1               1                  1   \n",
       "\n",
       "   Url_nunique  AccountSid_nunique  ...  EntityType_Url  EntityType_User  \\\n",
       "0            1                 148  ...               0             9081   \n",
       "1            3                   7  ...               4              320   \n",
       "2            1                   2  ...               0                1   \n",
       "3            3                1721  ...               4             1737   \n",
       "4            1                   3  ...               0                2   \n",
       "\n",
       "   EvidenceRole_Impacted  EvidenceRole_Related  SuspicionLevel_Incriminated  \\\n",
       "0                   9084                 20913                          0.0   \n",
       "1                   5484                 15041                          0.0   \n",
       "2                      2                     1                          0.0   \n",
       "3                   3477                  8775                          0.0   \n",
       "4                      4                     2                          0.0   \n",
       "\n",
       "   SuspicionLevel_Suspicious  LastVerdict_Malicious  \\\n",
       "0                        0.0                    0.0   \n",
       "1                    20453.0                 6645.0   \n",
       "2                        0.0                    0.0   \n",
       "3                       10.0                    1.0   \n",
       "4                        0.0                    0.0   \n",
       "\n",
       "   LastVerdict_NoThreatsFound  LastVerdict_Other  LastVerdict_Suspicious  \n",
       "0                         0.0                0.0                     0.0  \n",
       "1                         4.0                0.0                 13814.0  \n",
       "2                         0.0                0.0                     0.0  \n",
       "3                        10.0                0.0                    13.0  \n",
       "4                         0.0                0.0                     0.0  \n",
       "\n",
       "[5 rows x 156 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb1e6dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "train_data[\"label\"] = label_encoder.fit_transform(train_data[\"IncidentGrade\"])\n",
    "test_data[\"label\"] = label_encoder.transform(test_data[\"IncidentGrade\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25b688cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['BenignPositive', 'FalsePositive', 'TruePositive'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27e94da7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    218131\n",
       "1    135158\n",
       "2     95612\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e533a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data.drop(['IncidentId', 'IncidentGrade', 'label'], axis=1).values\n",
    "y = train_data[\"label\"].values\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size=0.1, stratify=y, random_state=67)\n",
    "\n",
    "X_test = test_data.drop(['IncidentId', 'IncidentGrade', 'label'], axis=1).values\n",
    "y_test = test_data[\"label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1db8d7fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training shape : (404010, 154)\n",
      "validation shape : (44891, 154)\n",
      "testing shape : (236267, 154)\n"
     ]
    }
   ],
   "source": [
    "print(f\"training shape : {X_train.shape}\")\n",
    "print(f\"validation shape : {X_validation.shape}\")\n",
    "print(f\"testing shape : {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9c11b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_validation = scaler.transform(X_validation)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "749c309d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class_counts  = np.bincount(y_train)\n",
    "class_weights = len(y_train) / (len(class_counts) * class_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd488b6",
   "metadata": {},
   "source": [
    "## prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f102fee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c042f69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce659e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(\n",
    "    torch.tensor(X_train, dtype=torch.float32),\n",
    "    torch.tensor(y_train, dtype=torch.long)\n",
    ")\n",
    "validation_dataset = TensorDataset(\n",
    "    torch.tensor(X_validation, dtype=torch.float32),\n",
    "    torch.tensor(y_validation, dtype=torch.long)\n",
    ")\n",
    "test_dataset = TensorDataset(\n",
    "    torch.tensor(X_test, dtype=torch.float32),\n",
    "    torch.tensor(y_test, dtype=torch.long)\n",
    ")\n",
    "train_loader = DataLoader(train_dataset, batch_size=2048, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=2048)\n",
    "test_loader = DataLoader(test_dataset, batch_size=2048)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026cbbb7",
   "metadata": {},
   "source": [
    "## create the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70926be6",
   "metadata": {},
   "source": [
    "### create the residual blocks class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54a3998a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.block=nn.Sequential(\n",
    "            nn.BatchNorm1d(in_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(in_dim, out_dim),\n",
    "            nn.BatchNorm1d(out_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(out_dim, out_dim)\n",
    "        )\n",
    "        self.shourtcut = (\n",
    "            nn.Linear(in_dim, out_dim) if in_dim != out_dim else nn.Identity()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.block(x) + self.shourtcut(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ff0182",
   "metadata": {},
   "source": [
    "### create the model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03e1340e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualModel(nn.Module):\n",
    "    def __init__(self, in_dim, n_classes):\n",
    "        super().__init__()\n",
    "        self.input= nn.Linear(in_dim, 512)\n",
    "        self.blocks = nn.Sequential(\n",
    "            ResidualBlock(512, 512),\n",
    "            ResidualBlock(512,256),\n",
    "            ResidualBlock(256, 256),\n",
    "            ResidualBlock(256, 128),\n",
    "            ResidualBlock(128, 128)\n",
    "        )\n",
    "        self.head = nn.Sequential(\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(128, n_classes)\n",
    "        )\n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        for layer in self.modules():\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                nn.init.kaiming_normal_(layer.weight, nonlinearity=\"relu\")\n",
    "                nn.init.zeros_(layer.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input(x)\n",
    "        x = self.blocks(x)\n",
    "        return self.head(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd620e10",
   "metadata": {},
   "source": [
    "### create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "acfdb9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = X_train.shape[1]\n",
    "num_classes = 3\n",
    "\n",
    "model = ResidualModel(input_dim, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6d1ac3",
   "metadata": {},
   "source": [
    "### print the number of leanable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12022d49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1186563"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(parameter.numel() for parameter in model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b031882",
   "metadata": {},
   "source": [
    "## create the loss, optimizer and the learning rate decay scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6bb0e25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create cross entropy loss with class weight\n",
    "critertion = nn.CrossEntropyLoss(\n",
    "    weight= torch.tensor(class_weights, dtype=torch.float32).to(device),\n",
    ")\n",
    "\n",
    "# create adamw optimizer with a soft weight decay\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    weight_decay=0.0001\n",
    ")\n",
    "\n",
    "# create learning rate scheduler\n",
    "# first cycle take 10 epochs (T_0 = 10)\n",
    "# after that reset every 2 * last cycle length (T_mult = 2) \n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafe93cb",
   "metadata": {},
   "source": [
    "## train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1895512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Train Loss: 0.9332 | Val Loss: 0.8875 | Val Macro-F1: 0.5868\n",
      ">>>> New best saved (val macro-F1: 0.5868)\n",
      "Epoch 002 | Train Loss: 0.8512 | Val Loss: 0.8756 | Val Macro-F1: 0.6116\n",
      ">>>> New best saved (val macro-F1: 0.6116)\n",
      "Epoch 003 | Train Loss: 0.8242 | Val Loss: 0.8521 | Val Macro-F1: 0.6311\n",
      ">>>> New best saved (val macro-F1: 0.6311)\n",
      "Epoch 004 | Train Loss: 0.8059 | Val Loss: 0.8768 | Val Macro-F1: 0.6168\n",
      "Epoch 005 | Train Loss: 0.7939 | Val Loss: 0.8376 | Val Macro-F1: 0.6449\n",
      ">>>> New best saved (val macro-F1: 0.6449)\n",
      "Epoch 006 | Train Loss: 0.7811 | Val Loss: 0.8709 | Val Macro-F1: 0.6319\n",
      "Epoch 007 | Train Loss: 0.7726 | Val Loss: 0.8700 | Val Macro-F1: 0.5875\n",
      "Epoch 008 | Train Loss: 0.7661 | Val Loss: 0.8362 | Val Macro-F1: 0.5905\n",
      "Epoch 009 | Train Loss: 0.7602 | Val Loss: 0.8747 | Val Macro-F1: 0.5794\n",
      "Epoch 010 | Train Loss: 0.7581 | Val Loss: 0.8473 | Val Macro-F1: 0.5924\n",
      "Epoch 011 | Train Loss: 0.7790 | Val Loss: 0.8593 | Val Macro-F1: 0.5623\n",
      "Epoch 012 | Train Loss: 0.7697 | Val Loss: 0.8567 | Val Macro-F1: 0.5843\n",
      "Epoch 013 | Train Loss: 0.7627 | Val Loss: 0.8951 | Val Macro-F1: 0.5670\n",
      "Epoch 014 | Train Loss: 0.7556 | Val Loss: 0.8277 | Val Macro-F1: 0.6050\n",
      "Epoch 015 | Train Loss: 0.7510 | Val Loss: 0.9193 | Val Macro-F1: 0.5457\n",
      "Epoch 016 | Train Loss: 0.7468 | Val Loss: 0.8371 | Val Macro-F1: 0.5757\n",
      "Epoch 017 | Train Loss: 0.7434 | Val Loss: 0.8025 | Val Macro-F1: 0.6018\n",
      "Epoch 018 | Train Loss: 0.7389 | Val Loss: 0.8698 | Val Macro-F1: 0.5943\n",
      "Epoch 019 | Train Loss: 0.7355 | Val Loss: 0.8475 | Val Macro-F1: 0.5792\n",
      "Epoch 020 | Train Loss: 0.7312 | Val Loss: 0.9053 | Val Macro-F1: 0.5541\n",
      "Epoch 021 | Train Loss: 0.7286 | Val Loss: 0.8972 | Val Macro-F1: 0.5600\n",
      "Epoch 022 | Train Loss: 0.7257 | Val Loss: 0.8790 | Val Macro-F1: 0.5629\n",
      "Epoch 023 | Train Loss: 0.7234 | Val Loss: 0.8224 | Val Macro-F1: 0.6489\n",
      ">>>> New best saved (val macro-F1: 0.6489)\n",
      "Epoch 024 | Train Loss: 0.7203 | Val Loss: 0.8454 | Val Macro-F1: 0.6205\n",
      "Epoch 025 | Train Loss: 0.7174 | Val Loss: 0.8393 | Val Macro-F1: 0.5864\n",
      "Epoch 026 | Train Loss: 0.7147 | Val Loss: 0.8226 | Val Macro-F1: 0.5854\n",
      "Epoch 027 | Train Loss: 0.7127 | Val Loss: 0.8501 | Val Macro-F1: 0.5797\n",
      "Epoch 028 | Train Loss: 0.7108 | Val Loss: 0.7832 | Val Macro-F1: 0.6542\n",
      ">>>> New best saved (val macro-F1: 0.6542)\n",
      "Epoch 029 | Train Loss: 0.7099 | Val Loss: 0.8271 | Val Macro-F1: 0.6061\n",
      "Epoch 030 | Train Loss: 0.7089 | Val Loss: 0.8585 | Val Macro-F1: 0.5714\n",
      "Epoch 031 | Train Loss: 0.7304 | Val Loss: 0.7537 | Val Macro-F1: 0.6655\n",
      ">>>> New best saved (val macro-F1: 0.6655)\n",
      "Epoch 032 | Train Loss: 0.7278 | Val Loss: 0.8568 | Val Macro-F1: 0.6379\n",
      "Epoch 033 | Train Loss: 0.7245 | Val Loss: 0.8002 | Val Macro-F1: 0.6565\n",
      "Epoch 034 | Train Loss: 0.7233 | Val Loss: 0.7799 | Val Macro-F1: 0.6423\n",
      "Epoch 035 | Train Loss: 0.7209 | Val Loss: 0.7898 | Val Macro-F1: 0.6628\n",
      "Epoch 036 | Train Loss: 0.7185 | Val Loss: 0.9364 | Val Macro-F1: 0.4521\n",
      "Epoch 037 | Train Loss: 0.7177 | Val Loss: 0.8231 | Val Macro-F1: 0.6188\n",
      "Epoch 038 | Train Loss: 0.7141 | Val Loss: 0.8612 | Val Macro-F1: 0.6241\n",
      "Epoch 039 | Train Loss: 0.7129 | Val Loss: 0.7994 | Val Macro-F1: 0.6497\n",
      "Epoch 040 | Train Loss: 0.7106 | Val Loss: 0.7424 | Val Macro-F1: 0.6674\n",
      ">>>> New best saved (val macro-F1: 0.6674)\n",
      "Epoch 041 | Train Loss: 0.7085 | Val Loss: 0.7621 | Val Macro-F1: 0.6487\n",
      "Epoch 042 | Train Loss: 0.7064 | Val Loss: 0.7937 | Val Macro-F1: 0.6586\n",
      "Epoch 043 | Train Loss: 0.7044 | Val Loss: 0.7838 | Val Macro-F1: 0.6412\n",
      "Epoch 044 | Train Loss: 0.7030 | Val Loss: 0.7869 | Val Macro-F1: 0.6639\n",
      "Epoch 045 | Train Loss: 0.7012 | Val Loss: 0.7523 | Val Macro-F1: 0.6673\n",
      "Epoch 046 | Train Loss: 0.6994 | Val Loss: 0.7902 | Val Macro-F1: 0.6556\n",
      "Epoch 047 | Train Loss: 0.6979 | Val Loss: 0.7711 | Val Macro-F1: 0.6579\n",
      "Epoch 048 | Train Loss: 0.6958 | Val Loss: 0.7491 | Val Macro-F1: 0.6580\n",
      "Epoch 049 | Train Loss: 0.6938 | Val Loss: 0.7585 | Val Macro-F1: 0.6615\n",
      "Epoch 050 | Train Loss: 0.6921 | Val Loss: 0.7638 | Val Macro-F1: 0.6631\n",
      "Epoch 051 | Train Loss: 0.6898 | Val Loss: 0.7153 | Val Macro-F1: 0.6762\n",
      ">>>> New best saved (val macro-F1: 0.6762)\n",
      "Epoch 052 | Train Loss: 0.6877 | Val Loss: 0.7843 | Val Macro-F1: 0.6604\n",
      "Epoch 053 | Train Loss: 0.6856 | Val Loss: 0.7455 | Val Macro-F1: 0.6663\n",
      "Epoch 054 | Train Loss: 0.6843 | Val Loss: 0.7193 | Val Macro-F1: 0.6657\n",
      "Epoch 055 | Train Loss: 0.6823 | Val Loss: 0.7632 | Val Macro-F1: 0.6509\n",
      "Epoch 056 | Train Loss: 0.6803 | Val Loss: 0.7134 | Val Macro-F1: 0.6738\n",
      "Epoch 057 | Train Loss: 0.6790 | Val Loss: 0.7447 | Val Macro-F1: 0.6573\n",
      "Epoch 058 | Train Loss: 0.6765 | Val Loss: 0.7518 | Val Macro-F1: 0.6599\n",
      "Epoch 059 | Train Loss: 0.6753 | Val Loss: 0.7339 | Val Macro-F1: 0.6625\n",
      "Epoch 060 | Train Loss: 0.6731 | Val Loss: 0.7660 | Val Macro-F1: 0.6547\n",
      "Epoch 061 | Train Loss: 0.6716 | Val Loss: 0.7350 | Val Macro-F1: 0.6723\n",
      "Epoch 062 | Train Loss: 0.6700 | Val Loss: 0.7512 | Val Macro-F1: 0.6645\n",
      "Epoch 063 | Train Loss: 0.6685 | Val Loss: 0.7777 | Val Macro-F1: 0.6581\n",
      "Epoch 064 | Train Loss: 0.6672 | Val Loss: 0.7449 | Val Macro-F1: 0.6658\n",
      "Epoch 065 | Train Loss: 0.6661 | Val Loss: 0.7298 | Val Macro-F1: 0.6762\n",
      "Epoch 066 | Train Loss: 0.6654 | Val Loss: 0.7418 | Val Macro-F1: 0.6671\n",
      "Epoch 067 | Train Loss: 0.6645 | Val Loss: 0.7364 | Val Macro-F1: 0.6763\n",
      ">>>> New best saved (val macro-F1: 0.6763)\n",
      "Epoch 068 | Train Loss: 0.6642 | Val Loss: 0.7453 | Val Macro-F1: 0.6674\n",
      "Epoch 069 | Train Loss: 0.6636 | Val Loss: 0.7638 | Val Macro-F1: 0.6616\n",
      "Epoch 070 | Train Loss: 0.6634 | Val Loss: 0.7327 | Val Macro-F1: 0.6723\n",
      "Epoch 071 | Train Loss: 0.6889 | Val Loss: 0.7394 | Val Macro-F1: 0.6682\n",
      "Epoch 072 | Train Loss: 0.6885 | Val Loss: 0.7663 | Val Macro-F1: 0.6591\n",
      "Epoch 073 | Train Loss: 0.6881 | Val Loss: 0.7304 | Val Macro-F1: 0.6690\n",
      "Epoch 074 | Train Loss: 0.6869 | Val Loss: 0.7375 | Val Macro-F1: 0.6729\n",
      "Epoch 075 | Train Loss: 0.6859 | Val Loss: 0.7359 | Val Macro-F1: 0.6671\n",
      "Epoch 076 | Train Loss: 0.6855 | Val Loss: 0.7857 | Val Macro-F1: 0.6145\n",
      "Epoch 077 | Train Loss: 0.6845 | Val Loss: 0.7450 | Val Macro-F1: 0.6633\n",
      "Epoch 078 | Train Loss: 0.6827 | Val Loss: 0.7683 | Val Macro-F1: 0.6639\n",
      "Epoch 079 | Train Loss: 0.6827 | Val Loss: 0.7292 | Val Macro-F1: 0.6661\n",
      "Epoch 080 | Train Loss: 0.6816 | Val Loss: 0.7378 | Val Macro-F1: 0.6726\n",
      "Epoch 081 | Train Loss: 0.6795 | Val Loss: 0.7541 | Val Macro-F1: 0.6624\n",
      "Epoch 082 | Train Loss: 0.6776 | Val Loss: 0.7910 | Val Macro-F1: 0.6451\n",
      "Epoch 083 | Train Loss: 0.6775 | Val Loss: 0.7467 | Val Macro-F1: 0.6609\n",
      "Epoch 084 | Train Loss: 0.6765 | Val Loss: 0.7542 | Val Macro-F1: 0.6715\n",
      "Epoch 085 | Train Loss: 0.6751 | Val Loss: 0.7424 | Val Macro-F1: 0.6643\n",
      "Epoch 086 | Train Loss: 0.6734 | Val Loss: 0.7462 | Val Macro-F1: 0.6664\n",
      "Epoch 087 | Train Loss: 0.6720 | Val Loss: 0.7688 | Val Macro-F1: 0.6216\n",
      "\n",
      "Early stopping at epoch 87 — no improvement for 20 epochs.\n",
      "\n",
      "Best Val Macro-F1: 0.6763\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "epochs = 200\n",
    "patience = 20\n",
    "\n",
    "best_f1 = 0.0\n",
    "patience_now = 0\n",
    "train_history = []\n",
    "validation_history = []\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    # train\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        pred = model(X_batch)\n",
    "        loss = critertion(pred, y_batch)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * len(y_batch)\n",
    "    scheduler.step()\n",
    "    train_loss /= len(train_dataset)\n",
    "    train_history.append(train_loss)\n",
    "\n",
    "    # validate\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    validation_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in validation_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            pred = model(X_batch)\n",
    "            loss = critertion(pred, y_batch)\n",
    "            validation_loss += loss.item() * len(y_batch)\n",
    "            pred_out = pred.argmax(dim=1).cpu().numpy()\n",
    "            all_preds.extend(pred_out)\n",
    "    validation_loss /= len(validation_dataset)\n",
    "    valildation_f1_score = f1_score(y_validation, all_preds, average=\"macro\")\n",
    "    validation_history.append(valildation_f1_score)\n",
    "    print(f\"Epoch {epoch:03d} | Train Loss: {train_loss:.4f} | Val Loss: {validation_loss:.4f} | Val Macro-F1: {valildation_f1_score:.4f}\")\n",
    "\n",
    "    # early stopping\n",
    "    if valildation_f1_score > best_f1:\n",
    "        best_f1 = valildation_f1_score\n",
    "        patience_now = 0\n",
    "        torch.save(model.state_dict(), 'artifacts/best_model.pth')\n",
    "        print(f\">>>> New best saved (val macro-F1: {best_f1:.4f})\")\n",
    "    else:\n",
    "        patience_now += 1\n",
    "        if patience_now >= patience:\n",
    "            print(f\"\\nEarly stopping at epoch {epoch} — \"f\"no improvement for {patience} epochs.\")\n",
    "            break\n",
    "        \n",
    "# print best score after training \n",
    "print(f\"\\nBest Val Macro-F1: {best_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d7e1a3",
   "metadata": {},
   "source": [
    "## evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "42d60903",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_7268\\353753267.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('artifacts/best_model.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Macro-F1: 0.6572  (paper baseline: 0.87)\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('artifacts/best_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "all_preds = []\n",
    "with torch.no_grad():\n",
    "    for X_batch, _ in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        logits = model(X_batch)\n",
    "        preds  = logits.argmax(dim=1).cpu().numpy()\n",
    "        all_preds.extend(preds)\n",
    "\n",
    "test_f1 = f1_score(y_test, all_preds, average='macro')\n",
    "print(f\"Test Macro-F1: {test_f1:.4f}  (paper baseline: 0.87)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f64cd9",
   "metadata": {},
   "source": [
    "## save the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2902c695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config saved.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open('artifacts/model_config.json', 'w') as f:\n",
    "    json.dump({\n",
    "        'input_dim':   input_dim,\n",
    "        'num_classes': num_classes,\n",
    "        'classes':     list(label_encoder.classes_),\n",
    "        'best_val_f1': best_f1,\n",
    "        'test_f1':     test_f1,\n",
    "    }, f)\n",
    "\n",
    "print(\"Config saved.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
